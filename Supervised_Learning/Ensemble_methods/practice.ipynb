{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "403fbdee",
   "metadata": {},
   "source": [
    "1. make a imbalanced dataset and use both class weight and BalancedRandomForestRegressor\n",
    "2. Take iris dataset\n",
    "   Use randomforestregressor use OOB\n",
    "   do it with bootstraping random subspace, and random pathces\n",
    "   use hyperparameters which are specific to random forest\n",
    "   do feature selection using random forest\n",
    "   Feature importance based on mean decrease in impurity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7960f9",
   "metadata": {},
   "source": [
    "1. make a imbalanced dataset and use both class weight and BalancedRandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd63808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression (class_weight='balanced') ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       894\n",
      "           1       0.87      0.64      0.74       106\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.92      0.82      0.86      1000\n",
      "weighted avg       0.95      0.95      0.95      1000\n",
      "\n",
      "=== Balanced Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       894\n",
      "           1       0.72      0.82      0.77       106\n",
      "\n",
      "    accuracy                           0.95      1000\n",
      "   macro avg       0.85      0.89      0.87      1000\n",
      "weighted avg       0.95      0.95      0.95      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(n_samples=5000, n_features=10, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "\n",
    "brf = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "brf.fit(X_train, y_train)\n",
    "brf_preds = brf.predict(X_test)\n",
    "\n",
    "print(\"=== Logistic Regression (class_weight='balanced') ===\")\n",
    "print(classification_report(y_test, rf_preds))\n",
    "\n",
    "print(\"=== Balanced Random Forest ===\")\n",
    "print(classification_report(y_test, brf_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602dec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB score: 0.943\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris()\n",
    "X,y = iris.data, iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "baseline_rf = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "baseline_rf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"OOB score: {baseline_rf.oob_score_:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455e44bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Tuned OOB Score: 0.943\n",
      "Best Parameters:  {'n_estimators': 50, 'max_samples': None, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': True}\n",
      "\n",
      " Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
      "24 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "6 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 431, in fit\n",
      "    raise ValueError(\n",
      "ValueError: `max_sample` cannot be set if `bootstrap=False`. Either switch to `bootstrap=True` or set `max_sample=None`.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_forest.py\", line 448, in fit\n",
      "    raise ValueError(\"Out of bag estimation only available if bootstrap=True\")\n",
      "ValueError: Out of bag estimation only available if bootstrap=True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "7 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1382, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 436, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan 0.94285714        nan\n",
      "        nan 0.92380952        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4. Hyperparameter Grid\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False],\n",
    "    'max_samples': [0.5, 0.75, None],\n",
    "    'max_depth': [None, 5, 10, 20]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(oob_score=True, random_state=42)\n",
    "random_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=10, cv=3, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = random_search.best_estimator_\n",
    "print(f'\\n Tuned OOB Score: {best_rf.oob_score_:.3f}')\n",
    "print(\"Best Parameters: \", random_search.best_params_)\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "print(\"\\n Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e79da3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
